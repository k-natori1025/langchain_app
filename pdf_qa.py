import streamlit as st
from langchain.callbacks import get_openai_callback

from PyPDF2 import PdfReader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Qdrant
from langchain.chains import RetrievalQA

from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams

QDRANT_PATH = "./local_qdrant"
COLLECTION_NAME = "my_collection"


def init_page():
    st.set_page_config(
        page_title="Ask My PDF(s)",
        page_icon="ğŸ“‚"
    )
    st.sidebar.title("Nav")
    st.session_state.costs = []
    # emb_model_nameã‚’åˆæœŸåŒ–
    if 'emb_model_name' not in st.session_state:
        st.session_state.emb_model_name = "text-embedding-ada-002"

def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-3.5-16k", "GPT-4"))
    if model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo"
    elif model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo-16k"
    else:
        st.session_state.model_name = "gpt-4"
    
    # 300: æœ¬æ–‡ä»¥å¤–ã®æŒ‡ç¤ºã®ãƒˆãƒ¼ã‚¯ãƒ³æ•° (ä»¥ä¸‹åŒã˜)
    st.session_state.max_token = OpenAI.modelname_to_contextsize(st.session_state.model_name) - 300
    return ChatOpenAI(temperature=0, model_name=st.session_state.model_name)

def get_pdf_text():
    uploaded_file = st.file_uploader(
        label='Upload your PDF hereğŸ“‚',
        type='pdf' #ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’è¨±å¯ã™ã‚‹æ‹¡å¼µå­
    )
    if uploaded_file:
        pdf_reader = PdfReader(uploaded_file)
        text = '\n\n'.join([page.extract_text() for page in pdf_reader.pages])
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            model_name=st.session_state.emb_model_name,
            # é©åˆ‡ãª chunk size ã¯è³ªå•å¯¾è±¡ã®PDFã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ãŸã‚èª¿æ•´ãŒå¿…è¦
            # å¤§ããã—ã™ãã‚‹ã¨è³ªå•å›ç­”æ™‚ã«è‰²ã€…ãªç®‡æ‰€ã®æƒ…å ±ã‚’å‚ç…§ã™ã‚‹ã“ã¨ãŒã§ããªã„
            # é€†ã«å°ã•ã™ãã‚‹ã¨ä¸€ã¤ã®chunkã«ååˆ†ãªã‚µã‚¤ã‚ºã®æ–‡è„ˆãŒå…¥ã‚‰ãªã„
            chunk_size=500,
            chunk_overlap=0,
        )
        return text_splitter.split_text(text)
    else:
        return None

# ãƒ™ã‚¯ãƒˆãƒ«DBã‚’æ“ä½œã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æº–å‚™
def load_qdrant():
    client = QdrantClient(path=QDRANT_PATH)
    # qdrant cloud ã¸ã®ä¿å­˜ (æ¬¡ã®ç« ã§è©³ã—ãè©±ã—ã¾ã™)
    # client = QdrantClient(
    #     url="https://oreno-qdrant-db.us-east-1-0.aws.cloud.qdrant.io:6333",
    #     api_key="api-key-hoge123fuga456"
    # )

    # ã™ã¹ã¦ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’å–å¾—
    collections = client.get_collections().collections
    collection_names = [collection.name for collection in collections]

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆ
    if COLLECTION_NAME not in collection_names:
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã€æ–°ã—ãä½œæˆã—ã¾ã™
        client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=1536, distance=Distance.COSINE),
        )
        print('collection created')
    # clientã‚’ç”¨ã„ã¦ç”Ÿæˆã—ãŸEmbeddingã‚’ãƒ™ã‚¯ãƒˆãƒ«DBã®collection_nameã«ä¿ç®¡ã™ã‚‹
    return Qdrant(
        client=client,
        collection_name=COLLECTION_NAME, 
        embeddings=OpenAIEmbeddings()
    )

# PDFã®ãƒ†ã‚­ã‚¹ãƒˆã‚’Embeddingï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«DBã«ä¿å­˜ã™ã‚‹
def build_vector_store(pdf_text):
    qdrant = load_qdrant()
    # ä»¥ä¸‹ã§ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®Embeddingã¨ãƒ™ã‚¯ãƒˆãƒ«DBã¸ã®ä¿å­˜ãŒå®Ÿè¡Œã•ã‚Œã‚‹
    qdrant.add_texts(pdf_text)

# ãƒ™ã‚¯ãƒˆãƒ«DBã‚’åˆ©ç”¨ã—ã¦è³ªå•å¿œç­”ã‚’è¡Œã†LangChainã®æ©Ÿèƒ½ï¼ˆRetrievalQAï¼‰ã‚’å‘¼ã³å‡ºã™
def build_qa_model(llm):
    qdrant = load_qdrant()
    retriever = qdrant.as_retriever(
        search_type="similarity", # "mmr",  "similarity_score_threshold" ãªã©ã‚‚ã‚ã‚‹
        search_kwargs={"k":10} # æ–‡æ›¸ã‚’ä½•å€‹å–å¾—ã™ã‚‹ã‹ (default: 4)
    )
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff", 
        retriever=retriever,
        return_source_documents=True,
        verbose=True
    )

# RetrievalQGã‚’åˆ©ç”¨ã—ã¦è³ªå•å¿œç­”ã‚’å®Ÿè¡Œã™ã‚‹
def ask(qa, query):
    with get_openai_callback() as cb:
        answer = qa(query) # query / result / source_documents
    return answer, cb.total_cost


# PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®ãƒšãƒ¼ã‚¸ã®å®Ÿè£…
def page_pdf_upload_and_build_vector_db():
    st.title("PDF Upload")
    container = st.container()
    with container:
        pdf_text = get_pdf_text()
        if pdf_text:
            with st.spinner("Loading PDF ..."):
                build_vector_store(pdf_text)


# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸPDFã‚’ã‚‚ã¨ã«GPTã«è³ªå•ã™ã‚‹ãƒšãƒ¼ã‚¸ã®å®Ÿè£…
def page_ask_my_pdf():
    st.title("Ask My PDF(s)")
    llm = select_model()
    container = st.container()
    response_container = st.container()

    with container:
        query = st.text_input("Query: ", key="input")
        if not query:
            answer = None
        else:
            qa = build_qa_model(llm)
            if qa:
                with st.spinner("ChatGPT is typing ..."):
                    answer, cost = ask(qa, query)
                st.session_state.costs.append(cost)
            else:
                answer = None

        if answer:
            with response_container:
                st.markdown("## Answer")
                st.write(answer)


def main():
    init_page()

    # ãƒšãƒ¼ã‚¸ã®åˆ‡ã‚Šæ›¿ãˆ
    selection = st.sidebar.radio("Go to", ["PDF Upload", "Ask My PDF(s)"])
    if selection == "PDF Upload":
        page_pdf_upload_and_build_vector_db()
    elif selection == "Ask My PDF(s)":
        page_ask_my_pdf()

    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")

# ãƒ™ã‚¯ãƒˆãƒ«DBã®ä¸­èº«ã‚’ç¢ºèª
# client = QdrantClient(path=QDRANT_PATH)
# collection_info = client.get_collection(collection_name="my_collection")
# print(f"Collection Info: {collection_info}")
# vectors = client.scroll(
#     collection_name="my_collection",
#     limit=10,  # å¿…è¦ã«å¿œã˜ã¦é©åˆ‡ãªæ•°ã‚’è¨­å®š
# )
# for vector in vectors[0]:
#     print(f"ãƒ™ã‚¯ãƒˆãƒ«DB: {vector}")


if __name__ == '__main__':
    main()
